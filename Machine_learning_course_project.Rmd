---
title: "Untitled"
output: html_document
---
##SYNOPSIS

Wearable devices can predict what you are doing through the movement of the body. The data generated by these wearable devices can be collected and used to make predictions about the activity the wearer was performing at the time of specific measurements. This project is an attempt to gather, analyze and build such a prediction model using techniques of Practical Machine Learning. The resulting predictor was able to predict 20 out of 20 test values without a misprediction.

 this report should describe:
 
 "how you built your model"
."how you used cross validation"
."what you think the expected out of sample error is"
."why you made the choices you did"

##Loading and Processing train/test Data


```{r}
library(AppliedPredictiveModeling)
library(caret)
library(randomForest)
```

Given both training and test data from the following study:

```{r}

# Download data

setwd("C:/Users/lsharifi/Desktop/Rot2/coursera/Course 8/Course_Project/")

#loading Train Dataset
url_raw_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
file_dest_training <- "C:/Users/lsharifi/Desktop/Rot2/coursera/Course 8/Course_Project/pml-training.csv"
download.file(url=url_raw_training, destfile=file_dest_training)

#Loading Test Dataset
url_raw_testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
file_dest_testing <- "C:/Users/lsharifi/Desktop/Rot2/coursera/Course 8/Course_Project/pml-testing.csv"
download.file(url=url_raw_testing, destfile=file_dest_testing)


```

##(Clean and) Remove invalid predictors

First all blank('""'), '#DIV/0' and 'NA' values are converted to 'NA'. In order to run the machine learning algorithms, the features used cannot contain any  NA  values so any Columns containing 'NA' are removed from both downloaded data sets.

```{r, echo=TRUE}

# Import the data treating empty values as NA.
df_training <- read.csv(file_dest_training, na.strings=c("NA","#DIV/0!", ""), header=TRUE)
df_training<-df_training[,colSums(is.na(df_training)) == 0]

df_testing <- read.csv(file_dest_testing, na.strings=c("NA","#DIV/0!", ""), header=TRUE)
df_testing<-df_testing[,colSums(is.na(df_testing)) == 0]

```

From the structure of the data, we can see that the first 6 variables user_name ,  raw_timestamp_part_1 ,  raw_timestamp_part_2 ,  cvtd_timestamp ,  new_window ,  num_window  are simply administrative parameters and are unlikely to help us predict the activity the subjects are performing. V1 also seems to be a serial number Therefore we can remove it from the dataset , we are going to leave those 7 columns out before we build the algorithm

```{r}

df_training <-df_training[,-c(1:7)]
df_testing <-df_testing[,-c(1:7)]

```


##Data Partitioning and Prediction Process for Cross Validation

Forthis project, we will focus on using the two most widely-used, most accurate prediction algorithms,

We set  test  set aside and split the  train  data into two sections for cross validation. We will allocate 75% of the data to train the model and 25% to validate it.

```{r}
inTraining <- createDataPartition(df_training $classe, p = 0.75, list = FALSE)
training.data.df <- df_training [inTraining, ]
testing.data.df  <- df_training [-inTraining, ]

```

##Create the prediction model :

1- random forest(rf)
First, I will use random forest to build the first model. 

```{r}
set.seed(666)
library(randomForest)
# run the random forest algorithm on the training data set
model_rfFit <- randomForest(classe~., data = training.data.df , method ="rf", prox = TRUE)
print(model_rfFit)

# use model to predict on testing data set
rfPred <- predict(model_rfFit , testing.data.df)
print(rfPred)

# predicted result
confusionMatrix(rfPred, testing.data.df$classe)

```


2-Classification Tree(rpart)

```{r}
set.seed(666)
library(rpart)
model_rparFit <- train(classe ~ ., data = training.data.df, method="rpart")
print(model_rparFit, digits=3)

# use model to predict on testing data set
rpart_Pred <- predict(model_rparFit , testing.data.df)
print(rpart_Pred , digits=3)

# predicted result
confusionMatrix(rpart_Pred , testing.data.df$classe)

```

Next, we will try the Generalized Boosted Regression Models.

3-Generalized Boosted Regression Models(gmb)

```{r}
set.seed(666)
library('gbm')
library('survival')
# run the generalized boosted regression model
gbmFit <- train(classe~., data = training.data.df, method ="gbm", verbose = FALSE)
print(gbmFit, digits=3)

# use model to predict on testing data set
gbmPred <- predict(gbmFit, testing.data.df)
print(gbmPred, digits=3)

# predicted result
confusionMatrix(gbmPred, testing.data.df$classe)

```

